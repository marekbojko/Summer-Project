{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "import math\n",
    "from scipy import stats\n",
    "from bitarray import bitarray\n",
    "import pickle\n",
    "import community\n",
    "from bitarray import bitarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian random field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fftind(size):\n",
    "    \"\"\" Returns a numpy array of shifted Fourier coordinates k_x k_y.\n",
    "        \n",
    "        Input:\n",
    "        size (integer): The size of the coordinate array to create\n",
    "        \n",
    "        Output:\n",
    "            k_ind, numpy array of shape (2, size, size) with:\n",
    "                k_ind[0,:,:]:  k_x components\n",
    "                k_ind[1,:,:]:  k_y components\n",
    "    \"\"\"\n",
    "    k_ind = np.mgrid[:size, :size] - int( (size + 1)/2 )\n",
    "    k_ind = scipy.fftpack.fftshift(k_ind)\n",
    "    return( k_ind )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_random_field(alpha = 3.0, size = 100, flag_normalize = True):\n",
    "    \"\"\" \n",
    "    Returns a numpy array of sizexsize discrete Gaussian random field\n",
    "        \n",
    "    Input:\n",
    "    alpha (double, default = 3.0): \n",
    "        The power of the power-law momentum distribution\n",
    "    size (integer, default = 128):\n",
    "        The size of the square output Gaussian Random Fields\n",
    "    flag_normalize (boolean, default = True):\n",
    "        Normalizes the Gaussian Field:\n",
    "            - to have an average of 0.0\n",
    "            - to have a standard deviation of 1.0\n",
    "    Output:\n",
    "    gfield (numpy array of shape (size, size)):\n",
    "        The random gaussian random field\n",
    "\n",
    "    Example:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    example = gaussian_random_field()\n",
    "    plt.imshow(example)\n",
    "    \"\"\"\n",
    "        \n",
    "        # Defines momentum indices\n",
    "    k_idx = fftind(size)\n",
    "\n",
    "        # Defines the amplitude as a power law 1/|k|^(alpha/2)\n",
    "    amplitude = np.power( k_idx[0]**2 + k_idx[1]**2 + 1e-10, -alpha/4.0 )\n",
    "    amplitude[0,0] = 0\n",
    "    \n",
    "        # Draws a complex gaussian random noise with normal\n",
    "        # (circular) distribution\n",
    "    noise = np.random.normal(size = (size, size)) \\\n",
    "        + 1j * np.random.normal(size = (size, size))\n",
    "    \n",
    "        # To real space\n",
    "    gfield = np.fft.ifft2(noise * amplitude).real\n",
    "    \n",
    "        # Sets the standard deviation to one\n",
    "    if flag_normalize:\n",
    "        gfield = gfield - np.mean(gfield)\n",
    "        gfield = gfield/np.std(gfield)\n",
    "        \n",
    "    return gfield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some MAB algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def block_ucl(prior_means,prior_variance,variance,n_arms,time_horizon, arms, n, m_bar, random_rewards = True):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    prior_means - an array of prior means about the pay-offs of the arms\n",
    "    prior_variance - prior variance characterising the prior Gaussian distribution, constant for all arms\n",
    "    variance - variance of Gaussian distributions of each arm, constant for all arms, assumed known before the game begins\n",
    "    n_arms - number of arms of the MAB\n",
    "    time_horizon - number of time steps of the game\n",
    "    arms - set of arms, either input as a probability distribtion (Gaussian) or as an array of pay-offs for each arm\n",
    "    random_rewards - True if the rewards are drawn i.i.d. from Gaussian distribution at each time step\n",
    "    \n",
    "    Output : allocation sequence of arms over the time horizon\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #### Initialisation\n",
    "    \n",
    "    # n[i] denotes the number of pulls of the arm i in t-1 peridos\n",
    "    # n = np.zeros(n_arms)\n",
    "    \n",
    "    # m_bar[i] denotes the mean pay-off as observed in t-1 periods\n",
    "    # m_bar = np.zeros(n_arms)\n",
    "    \n",
    "    # normalise variance\n",
    "    delta_sq = variance / prior_variance\n",
    "    \n",
    "    # K is a tuner variable\n",
    "    K = math.sqrt(2*math.pi*math.e)\n",
    "    \n",
    "    # rewards array\n",
    "    rewards = np.zeros(time_horizon)\n",
    "    \n",
    "    # allocation sequence (output)\n",
    "    alloc_seq = np.zeros(time_horizon)\n",
    "    \n",
    "    # initialise the values of the heuristic function for each arm\n",
    "    Q = np.zeros(n_arms)\n",
    "    \n",
    "    \n",
    "    #### Iteration\n",
    "    # at each allocation round pick the arm with maximum upper credible limit\n",
    "    \n",
    "    # let l be the smallest index s.t. T<2^l\n",
    "    l = math.ceil(math.exp(math.log(T)/2))\n",
    "    \n",
    "    \n",
    "    for k in range(1,l+1):\n",
    "        \n",
    "        # let bk be the total number of blocks in frame fk:\n",
    "        bk = math.ceil((2**(k-1))/k)\n",
    "        \n",
    "        for r in range(1,bk+1):\n",
    "            tau = 2**(k-1) + (r-1)*k\n",
    "            \n",
    "            for i in range(n_arms):\n",
    "                # Compute a heuristic value for the current arm\n",
    "                Q[i] = (delta_sq*prior_means[i]+n[i]*m_bar[i])/(delta_sq+n[i]) + math.sqrt(variance/(delta_sq+n[i]))*norm.ppf(1-1/(K*(tau)))\n",
    "            \n",
    "            # select an arm with the maximum value of the heuristic function\n",
    "            i_hat = np.argmax(Q)\n",
    "            \n",
    "            #print (k,tau,2**(k)-tau)\n",
    "            \n",
    "            if 2**(k)-tau >= k:\n",
    "                \n",
    "                #print (\"1\")\n",
    "                \n",
    "                # select the same arm for the whole duration of the block\n",
    "                for t in range(tau,tau+k):\n",
    "                    \n",
    "                    # terminate the algorithm and return the allocation sequence if the we are past the last time step\n",
    "                    if t-1>=time_horizon:\n",
    "                        return alloc_seq\n",
    "                    \n",
    "                    #print(\"if\",t-1)\n",
    "                    \n",
    "                    if random_rewards == True:\n",
    "                        # initialise a list of rewards\n",
    "                        all_rewards = [arms[i].draw() for i in range(n_arms)]\n",
    "                    else:\n",
    "                        all_rewards = arms\n",
    "                    \n",
    "                    alloc_seq[t-1] = i_hat\n",
    "                \n",
    "                    #collect reward\n",
    "                    rewards[t-1] = all_rewards[i_hat]\n",
    "                    \n",
    "                    # update variables\n",
    "                    m_bar[i_hat] = (n[i_hat]*m_bar[i_hat]+all_rewards[i_hat])/(n[i_hat]+1)\n",
    "                    n[i_hat] +=1\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                #print (\"2\")\n",
    "                \n",
    "                \n",
    "                for t in range(tau,2**(k)):\n",
    "                    \n",
    "                    # terminate the algorithm and return the allocation sequence if the we are past the last time step\n",
    "                    if t-1>=time_horizon:\n",
    "                        return alloc_seq\n",
    "                    \n",
    "                    #print(\"else\",t-1)\n",
    "                    \n",
    "                    if random_rewards == True:\n",
    "                        # initialise a list of rewards\n",
    "                        all_rewards = [arms[i].draw() for i in range(n_arms)]\n",
    "                    else:\n",
    "                        all_rewards = arms\n",
    "                    \n",
    "                    \n",
    "                    alloc_seq[t-1] = i_hat\n",
    "                \n",
    "                    #colect reward\n",
    "                    rewards[t-1] = all_rewards[i_hat]\n",
    "                    \n",
    "                    # update variables\n",
    "                    m_bar[i_hat] = (n[i_hat]*m_bar[i_hat]+all_rewards[i_hat])/(n[i_hat]+1)\n",
    "                    n[i_hat] +=1\n",
    "                    \n",
    "    return alloc_seq, rewards, n, m_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def deterministic_ucl(prior_means,prior_variance,variance,n_arms,time_horizon,arms,  n, m_bar, random_rewards=True):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    prior_means - an array of prior means about the pay-offs of the arms\n",
    "    prior_variance - prior variance characterising the prior Gaussian distribution, constant for all arms\n",
    "    variance - variance of Gaussian distributions of each arm, constant for all arms, assumed known before the game begins\n",
    "    n_arms - number of arms of the MAB\n",
    "    time_horizon - number of time steps of the game\n",
    "    arms - a list or array of arms together with their reward distribution\n",
    "    \n",
    "    Output : allocation sequence of arms over the time horizon\n",
    "    \"\"\"\n",
    "    \n",
    "    #### Initialisation\n",
    "    \n",
    "    # n[i] denotes the number of pulls of the arm i in t-1 peridos\n",
    "    # n = np.zeros(n_arms)\n",
    "    \n",
    "    # m_bar[i] denotes the mean pay-off as observed in t-1 periods\n",
    "    # m_bar = np.zeros(n_arms)\n",
    "    \n",
    "    # normalise variance\n",
    "    delta_sq = variance / prior_variance\n",
    "    \n",
    "    # K is a tuner variable\n",
    "    K = math.sqrt(2*math.pi*math.e)\n",
    "    \n",
    "    # rewards array\n",
    "    rewards = np.zeros(time_horizon)\n",
    "    \n",
    "    # allocation sequence (output)\n",
    "    alloc_seq = np.zeros(time_horizon)\n",
    "    \n",
    "    # initialise the values of the heuristic function for each arm\n",
    "    Q = np.zeros(n_arms)\n",
    "    \n",
    "    #### Iteration\n",
    "    # at each time pick the arm with maximum upper credible limit (UCL)\n",
    "    for t in range(time_horizon):\n",
    "        \n",
    "        if random_rewards==True:\n",
    "            # initialise a list of rewards\n",
    "            all_rewards = [arms[i].draw() for i in range(n_arms)]\n",
    "        else:\n",
    "            all_rewards = arms\n",
    "        \n",
    "        for i in range(n_arms):\n",
    "            # Compute a heuristic value for the current arm\n",
    "            Q[i] = (delta_sq*prior_means[i]+n[i]*m_bar[i])/(delta_sq+n[i]) + (math.sqrt(variance/(delta_sq+n[i])))*norm.ppf(1-1/(K*(t+1)))\n",
    "        \n",
    "        #print(\"Q:\",Q)\n",
    "        #print('argmaxQ:',np.argmax(Q),'maxQ:',np.max(Q))\n",
    "        \n",
    "        # select an arm with the highest heuristic function value\n",
    "        selected_arm = np.argmax(Q)\n",
    "        alloc_seq[t] = selected_arm\n",
    "        \n",
    "        \n",
    "        # collect reward m_real\n",
    "        rewards[t] = all_rewards[selected_arm]\n",
    "        \n",
    "        #print ('all rewards:', all_rewards)\n",
    "        \n",
    "        # update variables\n",
    "        m_bar[selected_arm] = (n[selected_arm]*m_bar[selected_arm] + all_rewards[selected_arm]) / (n[selected_arm] + 1)\n",
    "        n[selected_arm] += 1\n",
    "        \n",
    "        #print ('m_bar:',m_bar)\n",
    "        #print ('n:',n)\n",
    "    \n",
    "    return alloc_seq, rewards, n, m_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_min_diff(arr, n): \n",
    "    \"\"\"\n",
    "    Returns minimum difference between any pair of elements in an array\n",
    "    \n",
    "    arr - numpy array\n",
    "    n - number of elements in the array used in the process\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort array in non-decreasing order \n",
    "    arr = sorted(arr) \n",
    "  \n",
    "    # Initialize difference as infinite \n",
    "    diff = 10**20\n",
    "  \n",
    "    # Find the min diff by comparing adjacent \n",
    "    # pairs in sorted array \n",
    "    for i in range(n-1): \n",
    "        if abs(arr[i+1] - arr[i]) < diff: \n",
    "            diff = abs(arr[i+1] - arr[i]) \n",
    "  \n",
    "    # Return min diff \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def field_to_arms(rand_field):\n",
    "    \"\"\"\n",
    "    transforms an nxn grid generated as a random field to set of n^2 arms\n",
    "    \n",
    "    rand_field - Gaussian random field\n",
    "    \"\"\"\n",
    "    return rand_field.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arms_to_field(arms,n):\n",
    "    \"\"\"\n",
    "    Transforms an allocation sequence to sequence of 2D coordinates in the same structure as the field\n",
    "    \n",
    "    arms - an allocation sequence\n",
    "    \"\"\"\n",
    "    return arms%n,arms//n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### This should be useful when we add network dynamics\n",
    "\n",
    "\n",
    "class Graph(nx.MultiDiGraph):\n",
    "    \"\"\"Soe useful methods for multi directed graph\"\"\"\n",
    "    pos=None\n",
    "    _label=None\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self._label:\n",
    "            return self._label\n",
    "        return nx.MultiDiGraph.__repr__(self)\n",
    "    \n",
    "    def levels_layout(self,ranks=None,xpos=None):\n",
    "        pos={}\n",
    "        refpos=nx.spring_layout(self)\n",
    "        if not isinstance(xpos,dict):\n",
    "            xpos={i:j for i,j in zip(self.nodes(),xpos ) }\n",
    "        maxx,maxy=np.max(refpos.values(),axis=0)\n",
    "        for i,d in self.nodes(data=True):\n",
    "            if not xpos is None and i in xpos:\n",
    "                x=xpos[i]\n",
    "            else:\n",
    "                x= np.random.random()*maxx\n",
    "            if ranks is None:\n",
    "                y=d['height']*maxy\n",
    "            else:\n",
    "                y=ranks[i]\n",
    "            pos[i]=x,y\n",
    "        self.pos=pos\n",
    "\n",
    "    def plot(self,newfig=True,hold=False,labels=None,edge_labels=None,nscale=1,minsize=0.001,**kwargs):\n",
    "        '''Use matplotlib to plot the network'''\n",
    "        \n",
    "        if self.pos is None:\n",
    "            pos=self.pos=nx.spring_layout(self)\n",
    "        else:\n",
    "            pos=self.pos\n",
    "        if newfig:\n",
    "            plt.figure()\n",
    "        node_size=np.ones(len(self.node) ) *kwargs.get('node_size',1)\n",
    "        node_size[node_size<minsize]=0\n",
    "        node_size/=np.max(node_size)/2.\n",
    "        node_size[node_size>0]=np.clip(node_size[node_size>0],0.1,None)*nscale\n",
    "\n",
    "\n",
    "        node_size[np.random.random(node_size.shape )<kwargs.get('subsample',0)  ]=0\n",
    "        nodidx={n:i for i,n in enumerate(self.nodes()) }\n",
    "\n",
    "        edge_width=kwargs.get('edge_width',1)\n",
    "        if edge_width:\n",
    "            sign=kwargs.get('sign',0)\n",
    "            if not sign or sign<0:\n",
    "                nx.draw_networkx_edges(self,pos=pos,edgelist=[(i,j) for i,j,d in\n",
    "                    self.edges(data=True) if d.get('weight',0)<0 and node_size[nodidx[i]]*node_size[nodidx[j]]>0],\n",
    "                    edge_color='r',width=edge_width )\n",
    "            if not sign or sign>0:\n",
    "                nx.draw_networkx_edges(self,pos=pos,edgelist=[(i,j) for i,j,d in\n",
    "                    self.edges(data=True) if d.get('weight',0)>=0 and node_size[nodidx[i]]*node_size[nodidx[j]]>0.],\n",
    "                    edge_color='b',width=edge_width )\n",
    "        nx.draw_networkx_nodes(self,pos=pos ,node_size=node_size*200.,linewidths=0,\n",
    "                node_color= ifelse('node_color' in kwargs, np.array(kwargs.get('node_color',[])),'blue') )\n",
    "        if labels is None:\n",
    "            labels={n:str(n) for n in self.nodes() }\n",
    "        elif not isinstance(labels,dict):\n",
    "            labels={n:labels[i] for i,n in enumerate(self.nodes()) }\n",
    "        nx.draw_networkx_labels(self,pos=pos,labels={n:l for n,l in labels.items() if node_size[nodidx[n]]>0} )\n",
    "        if not edge_labels is None:\n",
    "            if edge_labels=='weights':\n",
    "                #print [self.edge[j][i][0] for i,j,d in\n",
    "                    #self.edges(data=True)]\n",
    "                edge_labels={(i,j):'{:.2f},{:.2f}'.format(self.edge[i][j][0]['weight'],self.edge[j][i][0]['weight']) for i,j,d in\n",
    "                    self.edges(data=True) if # self.edge[i][j][0]['weight']>-self.edge[j][i][0]['weight'] and\n",
    "                      node_size[nodidx[i]]*node_size[nodidx[j]]>0}\n",
    "            nx.draw_networkx_edge_labels(self,pos=pos,edge_labels= edge_labels )\n",
    "        if 'title' in kwargs:\n",
    "            plt.title(kwargs['title'])\n",
    "        if 'xlabel' in kwargs:\n",
    "            plt.xlabel(kwargs['xlabel'])\n",
    "        if 'ylabel' in kwargs:\n",
    "            plt.ylabel(kwargs['ylabel'])\n",
    "        if not hold:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (3, 4)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "G.add_nodes_from(range(5))\n",
    "\n",
    "A = nx.complete_graph(5)\n",
    "\n",
    "A.nodes()\n",
    "A.edges()\n",
    "\n",
    "A.add_weighted_edges_from((u,v,random.random()) for u,v in A.edges())\n",
    "A.edges()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_weights_complete_graph(graph, const = True, comm_prop = 0.5):\n",
    "    \"\"\"\n",
    "    Add weights to a graph.\n",
    "    \n",
    "    Inputs:\n",
    "    graph - networkx type graph\n",
    "    const - True if the weights are constant\n",
    "    comm_prop - communication propensity in the network\n",
    "    \n",
    "    Output:\n",
    "    weighted graph\n",
    "    \"\"\"\n",
    "    \n",
    "    return graph.add_weighted_edges_from((u,v,comm_prop) for u,v in graph.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comm_graph_heavyside(n,a):\n",
    "    \"\"\"\n",
    "    Produces a complete graph with weights according to a smooth approximation to a heavy-side step function\n",
    "    \n",
    "    Inputs:\n",
    "    n - number of nodes\n",
    "    a - parameter input to the heavy-side step function\n",
    "    \n",
    "    Output:\n",
    "    complete weighted graph\n",
    "    \"\"\"\n",
    "    \n",
    "    # intialise the graph\n",
    "    G=nx.complete_graph(n)\n",
    "    \n",
    "    # add edges with weights\n",
    "    G.add_weighted_edges_from((u,v,heavy_side_step(u,v,a)) for u,v in G.edges())\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heavy_side_step(x,y,a):\n",
    "    \"\"\"\n",
    "    Compute a smooth approximation to a heavy-side step function of distance between x,y using the usual Euclidean metric\n",
    "    \"\"\"\n",
    "    return 1/(1+math.exp(a*abs(x-y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, {'weight': 0.45016600268752216}),\n",
       " (0, 2, {'weight': 0.401312339887548}),\n",
       " (0, 3, {'weight': 0.35434369377420455}),\n",
       " (0, 4, {'weight': 0.31002551887238755}),\n",
       " (0, 5, {'weight': 0.2689414213699951}),\n",
       " (0, 6, {'weight': 0.23147521650098232}),\n",
       " (0, 7, {'weight': 0.19781611144141822}),\n",
       " (0, 8, {'weight': 0.16798161486607552}),\n",
       " (0, 9, {'weight': 0.14185106490048777}),\n",
       " (1, 2, {'weight': 0.45016600268752216}),\n",
       " (1, 3, {'weight': 0.401312339887548}),\n",
       " (1, 4, {'weight': 0.35434369377420455}),\n",
       " (1, 5, {'weight': 0.31002551887238755}),\n",
       " (1, 6, {'weight': 0.2689414213699951}),\n",
       " (1, 7, {'weight': 0.23147521650098232}),\n",
       " (1, 8, {'weight': 0.19781611144141822}),\n",
       " (1, 9, {'weight': 0.16798161486607552}),\n",
       " (2, 3, {'weight': 0.45016600268752216}),\n",
       " (2, 4, {'weight': 0.401312339887548}),\n",
       " (2, 5, {'weight': 0.35434369377420455}),\n",
       " (2, 6, {'weight': 0.31002551887238755}),\n",
       " (2, 7, {'weight': 0.2689414213699951}),\n",
       " (2, 8, {'weight': 0.23147521650098232}),\n",
       " (2, 9, {'weight': 0.19781611144141822}),\n",
       " (3, 4, {'weight': 0.45016600268752216}),\n",
       " (3, 5, {'weight': 0.401312339887548}),\n",
       " (3, 6, {'weight': 0.35434369377420455}),\n",
       " (3, 7, {'weight': 0.31002551887238755}),\n",
       " (3, 8, {'weight': 0.2689414213699951}),\n",
       " (3, 9, {'weight': 0.23147521650098232}),\n",
       " (4, 5, {'weight': 0.45016600268752216}),\n",
       " (4, 6, {'weight': 0.401312339887548}),\n",
       " (4, 7, {'weight': 0.35434369377420455}),\n",
       " (4, 8, {'weight': 0.31002551887238755}),\n",
       " (4, 9, {'weight': 0.2689414213699951}),\n",
       " (5, 6, {'weight': 0.45016600268752216}),\n",
       " (5, 7, {'weight': 0.401312339887548}),\n",
       " (5, 8, {'weight': 0.35434369377420455}),\n",
       " (5, 9, {'weight': 0.31002551887238755}),\n",
       " (6, 7, {'weight': 0.45016600268752216}),\n",
       " (6, 8, {'weight': 0.401312339887548}),\n",
       " (6, 9, {'weight': 0.35434369377420455}),\n",
       " (7, 8, {'weight': 0.45016600268752216}),\n",
       " (7, 9, {'weight': 0.401312339887548}),\n",
       " (8, 9, {'weight': 0.45016600268752216})]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = comm_graph_heavyside(10,0.1)\n",
    "\n",
    "A.edges(data=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global b, N, payoff, K\n",
    "\n",
    "# K is number of arms of the multi-armed bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise network of agents\n",
    "G = comm_graph_heavyside(10,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise payoff and strategy fields\n",
    "def init(network) :\n",
    "    \"\"\"adds payoff and strategy fields to each node\n",
    "    \"\"\"\n",
    "    \n",
    "    global N \n",
    "    n = N = len(network)\n",
    "    cnt = 0\n",
    "    network.graph['degrees'] = [network.degree(node) for node in network.nodes()] #just to check for now, as we know the graph is complete\n",
    "    for i in range(n) :\n",
    "        network.node[i]['payoff'] = 0 #average pay-off from all observed rewards\n",
    "        network.node[i]['alloc_seq'] = np.empty(0) #this will be the array of payoff from the multi-armed bandit\n",
    "        network.node[i]['rewards'] = np.empty(0)\n",
    "        network.node[i]['strategy'] = None #UPDATE\n",
    "        network.node[i]['next strategy'] = None\n",
    "        network.node[i]['neighbors'] = network.neighbors(i) #all other nodes for now\n",
    "        network.node[i]['fitness'] = 0\n",
    "        network.node[i]['arm'] = 0 #current location of the agent\n",
    "        network.node[i]['prior means'] = np.zeros(K)\n",
    "        network.node[i]['m_bar'] = np.zeros(K)\n",
    "        network.node[i]['n'] = np.zeros(K)\n",
    "        network.node[i]['prior variance'] = 1\n",
    "        network.node[i]['variance'] = 1\n",
    "        network.node[i]['game played with'] = np.empty(0) #with whom was the game already played? i.e. with whome has this individual tried\n",
    "                                                        # to share information?\n",
    "        network.node[i]['information shared with'] = np.empty(0) # with whom of the neighbors was a subset of the information set during\n",
    "                                                            # the particular iteration?\n",
    "        \n",
    "    \n",
    "    # TO-DO fix later with evolutionary strategies - distribute evenly and randomly among players\n",
    "    \"\"\"while cnt < n/2 :\n",
    "        s = mt.floor(rd.random()*n)\n",
    "        if not network.node[s]['strategy'] :\n",
    "            network.node[s]['strategy'] = True\n",
    "            cnt = cnt + 1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialise_pos(network,field):\n",
    "    \"\"\"\n",
    "    Initialise the position of the agents in the field\n",
    "    \"\"\"\n",
    "    for i in range(len(network)):\n",
    "        if np.all(network.node[i]['prior means']==network.node[i]['prior means'][0]):\n",
    "            arm = random.randint(0,K)\n",
    "            network.node[i]['arm'] = arm\n",
    "            network.node[i]['n'][arm] += 1\n",
    "            network.node[i]['rewards'][arm] = field_to_arms(field)[arm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19781611144141822"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init(G)\n",
    "\n",
    "# print (G.nodes(data=True))\n",
    "# print (G.edges(data=True))\n",
    "\n",
    "G.edge[1][8]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def arm_selection(network,field,alg=deterministic_ucl):\n",
    "    \"\"\"\n",
    "    Performs one round when the agents select an arm based on a specified algorithm and assign the allocation\n",
    "    sequence and array of rewards to the corresponding agent.\n",
    "    \n",
    "    Inputs:\n",
    "    network - network of social interactions\n",
    "    field - Gaussian random field\n",
    "    alg - which allocation algorithm will be used (default: deterministic)\n",
    "    \"\"\"\n",
    "    \n",
    "    arms = field_to_arms(field)\n",
    "    \n",
    "    if alg == deterministic_ucl:\n",
    "        for i in range(len(network)):\n",
    "            priors = network.node[i]['prior mean']\n",
    "            prior_var = network.node[i]['prior variance']\n",
    "            variance = network.node[i]['variance']\n",
    "            n_arms = np.len(arms)\n",
    "            n_visits = network.node[i]['n']\n",
    "            avg_arms = network.node[i]['m_bar']\n",
    "            time_horizon = 1\n",
    "            a,b,n,m_bar = deterministic_ucl(priors,prior_var,variance,n_arms,time_horizon,arms,n_visits, avg_arms,random_rewards=False)\n",
    "            network.node[i]['alloc_seq'] = np.append(network.node[i]['alloc_seq'],field_to_arms(a,math.sqrt(n_arms)))\n",
    "            network.node[i]['rewards'] = np.append(network.node[i]['rewards'],b)\n",
    "            network.node[i]['prior mean'] = np.mean(network.node[i]['rewards']) #update priors to have them ready for next iteration \n",
    "            network.node[i]['n'] = network.node[i]['n'] + n\n",
    "            network.node[i]['m_bar'] = network.node[i]['m_bar'] + m_bar\n",
    "    \n",
    "    elif alg == block_ucl:\n",
    "        for i in range(len(network)):\n",
    "            priors = network.node[i]['prior mean']\n",
    "            prior_var = network.node[i]['prior variance']\n",
    "            variance = network.node[i]['variance']\n",
    "            n_arms = np.len(arms)\n",
    "            time_horizon = 1\n",
    "            a,b,n, m_bar = block_ucl(priors,prior_var,variance,n_arms,time_horizon,arms,n_visits, avg_arms, random_rewards=False)\n",
    "            network.node[i]['alloc_seq'] = np.append(network.node[i]['alloc_seq'],field_to_arms(a,math.sqrt(n_arms)))\n",
    "            network.node[i]['rewards'] = np.append(network.node[i]['rewards'],b)\n",
    "            network.node[i]['prior mean'] = np.mean(network.node[i]['rewards']) #update priors to have them ready for next iteration\n",
    "            network.node[i]['n'] = network.node[i]['n'] + n\n",
    "            network.node[i]['m_bar'] = network.node[i]['m_bar'] + m_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def information_sharing(network):\n",
    "    \"\"\"\n",
    "    Performs one step of information sharing\n",
    "    \"\"\"\n",
    "    \n",
    "    network.node[i]['game played with'] = np.empty(0) #with whom was the game already played? i.e. with whome has this individual tried\n",
    "                                                        # to share information?\n",
    "    network.node[i]['information shared with'] = np.empty(0) # with whom of the neighbors was a subset of the information set during\n",
    "                                                            # the particular iteration?\n",
    "    \n",
    "    for i in range(len(network)):\n",
    "        if network.node[i]['neighbors'] == network.node[i]['game played with']:\n",
    "            pass\n",
    "        \n",
    "        to_iterate_over = np.setdiff1d(network.node[i]['game played with'],network.node[i]['neighbors'])\n",
    "        for j in to_iterate_over:\n",
    "            \n",
    "            network.node[i]['game played with'] = np.append(network.node[i]['game played with'],j)\n",
    "            network.node[j]['game played with'] = np.append(network.node[j]['game played with'],i)\n",
    "            \n",
    "            if network.edge[i][j]['weight']*np.len(network.node[i]['alloc_seq']) < 1:\n",
    "                if network.edge[i][j]['weight'] > random.random():\n",
    "                    network.node[i][\"n\"] = network.node[j][\"n\"] = network.node[i][\"n\"] + network.node[j][\"n\"]\n",
    "                    network.node[i][\"m_bar\"] = network.node[j][\"m_bar\"] = network.node[i][\"m_bar\"] + network.node[j][\"m_bar\"]\n",
    "                    network.node[j]['information shared with'] = np.append(network.node[j]['information shared with'],i)\n",
    "                    network.node[i]['information shared with'] = np.append(network.node[i]['information shared with'],j)\n",
    "            else:\n",
    "                n_to_share = math.floor(network.edge[i][j]['weight']*np.len(network.node[i]['alloc_seq']))\n",
    "                \n",
    "                #i shares with j:\n",
    "                for arm, reward in zip(network.node[i]['alloc_seq'][-n_to_share:],network.node[i]['rewards'][-n_to_share:]):\n",
    "                    network.node[j]['rewards'][arm] = (network.node[j]['rewards'][arm]*network.node[j]['n'][arm] + reward)/(network.node[j]['n'][arm]+1)\n",
    "                    network.node[j]['n'][arm] += 1\n",
    "                    \n",
    "                #j shares with i:\n",
    "                for arm, reward in zip(network.node[j]['alloc_seq'][-n_to_share:],network.node[j]['rewards'][-n_to_share:]):\n",
    "                    network.node[i]['rewards'][arm] = (network.node[i]['rewards'][arm]*network.node[i]['n'][arm] + reward)/(network.node[i]['n'][arm]+1)\n",
    "                    network.node[i]['n'][arm] += 1\n",
    "                    \n",
    "                network.node[j]['information shared with'] = np.append(network.node[j]['information shared with'],i)\n",
    "                network.node[i]['information shared with'] = np.append(network.node[i]['information shared with'],j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "2 6\n",
      "3 7\n",
      "[2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([5,6,7])\n",
    "\n",
    "for u,v in zip(a,b):\n",
    "    print (u,v)\n",
    "    \n",
    "print (a[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option is to have communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def community_init(network) :\n",
    "    \"\"\"Initialise pay-offs based on community membership\"\"\"\n",
    "    n = len(network)\n",
    "    partition = community.best_partition(network)\n",
    "    community_index = sorted(set(partition.values()))\n",
    "    num_communities = max(community_index)+1\n",
    "    comm_strat = [True if k < num_communities/2 else False for k in community_index]\n",
    "    rd.shuffle(comm_strat)\n",
    "    network.graph['degrees'] =  [network.degree(node) \n",
    "                                for node in network.nodes()]\n",
    "    for i in range(n) :\n",
    "        network.node[i]['strategy'] = comm_strat[partition[i]]\n",
    "        network.node[i]['next strategy'] = None\n",
    "        network.node[i]['neighbors'] = network.neighbors(i)\n",
    "        network.node[i]['payoff'] = 0 #average pay-off from all observed rewards\n",
    "        network.node[i]['alloc_seq'] = [] #this will be the array of payoff from the multi-armed bandit\n",
    "        network.node[i]['rewards'] = []\n",
    "        network.node[i]['fitness'] = 0\n",
    "        network.node[i]['arm'] = 0 #current location of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def record_data(network, data_array):\n",
    "    \"\"\"take single iteration snapshot of node strategies\"\"\"\n",
    "    for n in network.nodes() :\n",
    "        data_array[n] = network.node[n]['strategy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_strategy(network, node):\n",
    "    \"\"\"return new strategy for a single node\"\"\"\n",
    "    global b\n",
    "    if not network.node[node]['neighbors'] : #in the case of an isolated vertex\n",
    "        return network.node[node]['strategy']\n",
    "    v = rd.choice(network.node[node]['neighbors'])\n",
    "    if network.node[node]['payoff'] < network.node[v]['payoff'] :\n",
    "        p = (network.node[v]['payoff'] - network.node[node]['payoff'])/(max(network.graph['degrees'][node], network.graph['degrees'][v])*b*100.0)\n",
    "        s = rd.random()\n",
    "        if (s < p) :\n",
    "            return network.node[v]['strategy']\n",
    "    return network.node[node]['strategy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strategy_update(network):\n",
    "    \"\"\"update strategy of each node\"\"\"\n",
    "    new_strategies = [new_strategy(network, u) for u in network.nodes()]\n",
    "    for q in network.nodes() :\n",
    "        network.node[q]['strategy'] = new_strategies[q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_network_game(network):\n",
    "    \"\"\"update node payoffs\"\"\"\n",
    "    for u in network.nodes() :\n",
    "        network.node[u]['payoff'] = np.mean(network.node[u]['rewards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accum_payoff(network, u):\n",
    "    \"\"\"return the acumulated payoff of node u\"\"\"\n",
    "    global payoff\n",
    "    p = 0\n",
    "    s_u = network.node[u]['strategy']\n",
    "    for v in network.node[u]['neighbors'] :\n",
    "        s_v = network.node[v]['strategy']\n",
    "        p += payoff[s_u][s_v]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sim(network,field,n_mix=10000,n_data=1000):\n",
    "    \"\"\"run the simulation for n_mix+n_data times and return data for last n_data iterations,\n",
    "    collect data on \"\"\"\n",
    "    global K\n",
    "    data = [bitarray([False for x in network.nodes()]) for y in range(int(n_data))]\n",
    "    for i in range(n_mix):\n",
    "        information_sharing(network)\n",
    "        arm_selection(network,field)\n",
    "    for j in range(n_data):\n",
    "        information_sharing(network)\n",
    "        arm_selection(network,field)\n",
    "        record_data_sharing(network,data[j])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def record_data(network, data_array) :\n",
    "    \"\"\"take single iteration snapshot of the rate of communication\"\"\"\n",
    "    for n in network.nodes() :\n",
    "        data_array[n] = np.len(network.node[n]['information shared with'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
