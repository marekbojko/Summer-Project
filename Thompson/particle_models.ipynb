{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf as mpl_pdf\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sys import argv, exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vicsek model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = 5000. \n",
    "dt = 1. \n",
    "nt = int(tf/dt)\n",
    "\n",
    "''' fixed_density != True  results in a box with sides [-L0/2, L0/2].\n",
    "    fixed_density = True  rescales the box size according to L = sqrt(N/density) '''\n",
    "fixed_density = False\n",
    "L0 = 10.\n",
    "density = 0.5\n",
    "\n",
    "''' The following parameters must given as lists/tuples/arrays.\n",
    "    So a single value must be given as e.g. [x,] or (x,)\n",
    "    When running from main.py, all combinations will be iterated over.\n",
    "    When running an animation, the first/only values will be used. '''\n",
    "N_list = (300,)#, 150, 200, 250, 300,)            # number of particles\n",
    "v0_list = (0.15,)                    # velocity as a fraction of L\n",
    "R_list = (1.0,)                     # interaction radius as a fraction of L\n",
    "eta_list = (0.1,)#list(np.linspace(0.01,0.5,10))+list(np.linspace(0.5,5.0,20))  # noise\n",
    "\n",
    "\n",
    "# -------------------- #\n",
    "#  Data and averaging  #\n",
    "# -------------------- #\n",
    "''' Ideally, the time for which the simulation is left to 'burn in' (before data\n",
    "    is taken) should scale appropriately with different parameter combinations.\n",
    "    Run python burn_in.py for the SMALLEST values of v0 & R you're using (these are\n",
    "    the slowest to burn in). This will fit a straight line for the burn-in time\n",
    "    dependence on N, with coefficients which you should assign to burn_coeff below.\n",
    "    You might want to run simulations with very different v0, R separately so that\n",
    "    they don't all need to have the slowest burn-in time.\n",
    "    WARNING: this doesn't work too well for large systems, small but non-zero eta!'''\n",
    "burn_coeff = [0, 1] # nt_burn = burn_coeff[0] x N + burn_coeff[1]\n",
    "\n",
    "# Number of repeated simulations per set of parameters. Minimum 2!\n",
    "repeats = 2\n",
    "\n",
    "# Number of samples involved in susceptibility and Binder cumulant error determination\n",
    "error_samples = 50\n",
    "\n",
    "# Save file name for statistics (do not include extension: .out will be added automatically)\n",
    "save_name = \"output\"\n",
    "\n",
    "# Save a snapshot of the final state for each parameter combination\n",
    "save_snapshots = True\n",
    "\n",
    "# --------- #\n",
    "#  Leaders  #\n",
    "# --------- #\n",
    "N_ldr = 0 # number of leaders\n",
    "ldr_weight = 9 # effective weight - no. normal particles in leader\n",
    "ldr_R = 1.5 # multiple of regular interaction radius\n",
    "\n",
    "''' Can have multiple leaders with different trajectories. These are angular frequencies,\n",
    "    so they will be multiplied by the current time. The N_ldr-N_ldr_traj leaders without\n",
    "    a pre-defined trajectory will obey the same rules as normal particles. '''\n",
    "ldr_traj = np.array([0.02]) # numpy array\n",
    "N_ldr_traj = min(len(ldr_traj), N_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(L, N, v0, R, eta):\n",
    "    ''' Initialise a single run '''\n",
    "    state = np.zeros( (N, 5) )\n",
    "    state[:,:2] = L*np.random.random( (N, 2) ) - 0.5*L # positions x,y\n",
    "    state[:,2] = 2*np.pi * np.random.random(N) # angle\n",
    "    state[:,3] = v0 * np.cos(state[:,2]) # x velocity\n",
    "    state[:,4] = v0 * np.sin(state[:,2]) # y velocity\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def step(state, L, N, v0, R, eta, t): \n",
    "    ''' Perform one step for all particles '''\n",
    "    \n",
    "    # Update positions\n",
    "    state[:,:2] = state[:,:2] + v0*dt*state[:,3:]\n",
    "    \n",
    "    # Periodic boundaries\n",
    "    crossedX = np.where(abs(state[:,0]) > 0.5*L)\n",
    "    crossedY = np.where(abs(state[:,1]) > 0.5*L)\n",
    "    state[crossedX,0] = state[crossedX,0] - np.sign(state[crossedX,0])*L\n",
    "    state[crossedY,1] = state[crossedY,1] - np.sign(state[crossedY,1])*L\n",
    "        \n",
    "    # Initialise heading with noise\n",
    "    heading = eta*np.random.random(N) - 0.5*eta\n",
    "    \n",
    "    # Use adjacency matrix to determine neighbours\n",
    "    A = squareform(pdist(state[:,:2]))\n",
    "    for i in range(N):\n",
    "        adj = np.where(A[i,:] < R)[0] # indices of adjacent particles\n",
    "        theta = state[adj,2] # angles of all adjacent particles\n",
    "\n",
    "        # Leaders must be treated separately on account of their weight\n",
    "        ldr_adj = np.where(A[i,:N_ldr] < ldr_R)[0]\n",
    "        ldr_theta = state[ldr_adj,2]\n",
    "\n",
    "        # Sum sin and cos of angles\n",
    "        sum_sin = np.sum(np.sin(theta)) + ldr_weight*np.sum(np.sin(ldr_theta))\n",
    "        sum_cos = np.sum(np.cos(theta)) + ldr_weight*np.sum(np.cos(ldr_theta))\n",
    "        \n",
    "        # Compute heading for this particle\n",
    "        heading[i] += np.arctan2(sum_sin, sum_cos)\n",
    "   \n",
    "    # Update state with new headings\n",
    "    state[:,2] = heading # Can add an angle here for waveyness\n",
    "    \n",
    "    # Some leaders may have pre-defined trajectories\n",
    "    state[:N_ldr_traj,2] = ldr_traj * t\n",
    "     \n",
    "    # Update velocities\n",
    "    state[:,3] = v0 * np.cos(state[:,2])\n",
    "    state[:,4] = v0 * np.sin(state[:,2])\n",
    "    \n",
    "    return\n",
    "        \n",
    "\n",
    "def order_parameter(state, V_coeff):\n",
    "    ''' Calculate order parameter (V) '''\n",
    "    \n",
    "    Vx = np.sum(state[:,3])\n",
    "    Vy = np.sum(state[:,4])\n",
    "    return np.sqrt(Vx*Vx + Vy*Vy) * V_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"------------------\")? (<ipython-input-6-1f30282716d6>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-1f30282716d6>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    print \"------------------\"\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"------------------\")?\n"
     ]
    }
   ],
   "source": [
    "# For parallel runs, index for this process given as argv\n",
    "if len(argv) > 1:\n",
    "    pid = int(argv[1])\n",
    "\n",
    "    # Separate save files for different processes\n",
    "    save_file = save_name + \"_p\" + str(pid) + \".out\"\n",
    "\n",
    "else:\n",
    "    pid = 0\n",
    "    save_file = save_name + \".out\"\n",
    "\n",
    "\n",
    "# eta_list is partitioned between the processes\n",
    "eta_list = eta_list[pid::Np]\n",
    "\n",
    "print (\"\")\n",
    "print (\"------------------\")\n",
    "print (\"| Process no. %02d |\") %pid\n",
    "print (\"------------------\")\n",
    "print (\"\")\n",
    "print (\"General simulation info:\")\n",
    "if fixed_density == True:\n",
    "    print \"     Fixed density: %g\" %density\n",
    "else:\n",
    "    print \"     Box size: %g x %g\" %(L0,L0)\n",
    "print \"     Simulation time: %g in %g steps of size %g\" %(tf,nt,dt)\n",
    "print \"     %d leaders active\" %N_ldr\n",
    "print \"     Save file: %s\" %save_file\n",
    "\n",
    "\n",
    "# Want to track how far we are through the parameter combinations\n",
    "parameter_combinations = len(N_list) * len(v0_list) * len(R_list) * len(eta_list)\n",
    "icomb = 0\n",
    "\n",
    "# Loop over particle numbers\n",
    "for N in N_list:\n",
    "    \n",
    "    # Adjust L if fixed density\n",
    "    if fixed_density == True:\n",
    "        L = np.sqrt(N/density)\n",
    "    else:\n",
    "        L = L0\n",
    "    \n",
    "    # Number of steps for burn-in period\n",
    "    nt_burn = int( round(burn_coeff[0]*N + burn_coeff[1]) )\n",
    "        \n",
    "    # Loop over velocities\n",
    "    for v0 in v0_list:\n",
    "        # Loop over interaction radii\n",
    "        for R in R_list:\n",
    "            # Loop over noise values\n",
    "            for eta in eta_list:\n",
    "\n",
    "                # Print current parameters\n",
    "                icomb += 1\n",
    "                print (\"\")\n",
    "                print (\"Parameter combination %d/%d\") %(icomb, parameter_combinations)\n",
    "                print (\"Current parameters: (N, v0, R, eta) = (%d, %g, %g, %g)\") %(N,v0,R,eta)\n",
    "                print \"%d steps for burn-in, %d steps with data-taking\" %(nt_burn,nt)\n",
    "\n",
    "                # Create empty arrays for repeats\n",
    "                V_mean_repeats = np.zeros(repeats)\n",
    "                Vsq_mean_repeats = np.zeros(repeats)\n",
    "                Vqu_mean_repeats = np.zeros(repeats)\n",
    "\n",
    "                # Loop over repeats\n",
    "                print \"Simulation:\"\n",
    "                for rep in range(repeats):\n",
    "\n",
    "                    # Print current repeat number\n",
    "                    print \"            %d/%d\" %(rep+1,repeats)\n",
    "\n",
    "                    # Create a brand new initial state\n",
    "                    state = model.init(L, N, v0, R, eta)\n",
    "\n",
    "                    # Burn-in period\n",
    "                    for t in range(nt_burn):\n",
    "\n",
    "                        # All particles take one step\n",
    "                        model.step(state, L, N, v0, R, eta, t)\n",
    "\n",
    "                    # Create empty array for order parameter time-series\n",
    "                    V_series = np.zeros(nt)\n",
    "       \n",
    "                    # Coefficients\n",
    "                    V_coeff = 1.0 / (N*v0) # normalisation factor for order parameter\n",
    "                    chi_coeff = L**2 # N/density\n",
    "                    \n",
    "                    # Loop over steps\n",
    "                    for t in range(nt):\n",
    "                        \n",
    "                        # All particles take one step\n",
    "                        model.step(state, L, N, v0, R, eta, t)\n",
    "                        \n",
    "                        # Order parameter is tracked\n",
    "                        V_series[t] = model.order_parameter(state, V_coeff)\n",
    " \n",
    "                    # Powers of the order parameter (that sounds cool)\n",
    "                    Vsq_series = V_series * V_series\n",
    "                    Vqu_series = Vsq_series * Vsq_series\n",
    "\n",
    "                    # Mean of these time series' added to arrays of repeats\n",
    "                    V_mean_repeats[rep] = np.mean(V_series)\n",
    "                    Vsq_mean_repeats[rep] = np.mean(Vsq_series)\n",
    "                    Vqu_mean_repeats[rep] = np.mean(Vqu_series)\n",
    "\n",
    "                # End loop over repeats\n",
    "\n",
    "                # Compute mean of multiple independent simulations\n",
    "                V_mean = np.mean(V_mean_repeats)\n",
    "                eV_mean = np.std(V_mean_repeats, ddof=1) / np.sqrt(repeats) # Std err on mean\n",
    "                Vsq_mean = np.mean(Vsq_mean_repeats)\n",
    "                Vqu_mean = np.mean(Vqu_mean_repeats)\n",
    "               \n",
    "                # Compute sample variance\n",
    "                ''' This gives +ve definite results with a much smaller error than obtained\n",
    "                    via method used below for Binder cumulant, which would involve \n",
    "                    sampling V, V^2 and using var = <V^2> - <V>^2.'''\n",
    "                V_var = np.var(V_mean_repeats, ddof=1)\n",
    "                eV_var = V_var * np.sqrt(2.0/(repeats-1)) # Std err on variance\n",
    "                \n",
    "                # Get susceptibility from variance\n",
    "                chi = V_var * chi_coeff\n",
    "                echi = eV_var * chi_coeff\n",
    "\n",
    "                # Compute Binder cumulant\n",
    "                ''' Use the Central Limit Theorem to obtain a normal distribution for\n",
    "                    the Binder cumulant, through sampling V^2 and V^4 distributions.\n",
    "                    This performs better than using only the mean of V^2 and V^4 and \n",
    "                    propagating standard errors on these means. '''\n",
    "                Vsq_std = np.std(Vsq_mean_repeats, ddof=1)\n",
    "                Vqu_std = np.std(Vqu_mean_repeats, ddof=1)\n",
    "                U_dist = np.zeros(error_samples)\n",
    "                for sample in range(error_samples):\n",
    "\n",
    "                    # Reject samples below 0 or above 1\n",
    "                    Vsq_sample = -1\n",
    "                    Vqu_sample = -1\n",
    "                    while Vsq_sample < 0 or Vsq_sample > 1:\n",
    "                        Vsq_sample = np.random.normal(Vsq_mean, Vsq_std)\n",
    "                    while Vqu_sample < 0 or Vqu_sample > 1:\n",
    "                        Vqu_sample = np.random.normal(Vqu_mean, Vqu_std)\n",
    "                    \n",
    "                    # Compute Binder cumulant for these samples\n",
    "                    U_dist[sample] = 1 - ( Vqu_sample / (3*Vsq_sample**2) )\n",
    "                \n",
    "                # Compute mean and standard error of Binder cumulant\n",
    "                U = np.mean(U_dist)\n",
    "                eU = np.std(U_dist) / np.sqrt(error_samples)\n",
    "\n",
    "                # Save results\n",
    "                print \"Saving results to \", save_file\n",
    "                with open(save_file, 'a') as f:\n",
    "                    f.write( \"%f %d %f %f %f %f %f %f %f %f %f \\n\" \\\n",
    "                            %(L, N, v0, R, eta, V_mean, eV_mean, chi, echi, U, eU) )\n",
    "                \n",
    "                # Save snapshot of final state for final repeat\n",
    "                if save_snapshots == True:\n",
    "\n",
    "                    # Create string for file name\n",
    "                    snap_name = \"snapshot_L%g_N%g_v%g_R%g_eta%g_t%d\" %(L,N,v0,R,eta,int(nt*dt))\n",
    "                    snap_file = snap_name.replace('.','-') + \".out\"\n",
    "\n",
    "                    # First line will be the parameters\n",
    "                    snapshot = np.zeros( (N+1, 5) )\n",
    "                    snapshot[0,:] = [L, N, v0, R, eta]\n",
    "                    snapshot[1:,:] = state\n",
    "\n",
    "                    print \"Saving snapshot of final state to \", snap_file\n",
    "                    np.savetxt(snap_file, snapshot)\n",
    "\n",
    "                            \n",
    "            # End loop over noise values\n",
    "        # End loop over interaction radii\n",
    "    # End loop over velocities\n",
    "# End loop over particle numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third argument variable can tell us to save figure(s)\n",
    "if len(argv) > 3 and argv[3] == 'save':\n",
    "    save = True\n",
    "else:\n",
    "    save = False\n",
    "\n",
    "#####################\n",
    "## Plot a snapshot ##\n",
    "#####################\n",
    "if argv[1] == 'state':\n",
    "\n",
    "    # Load data given as second argument variable\n",
    "    input_data = np.loadtxt(argv[2])\n",
    "    \n",
    "    # Separate into parameters and state\n",
    "    L, N, v0, R, eta = input_data[0,:]\n",
    "    state = input_data[1:,:]\n",
    "\n",
    "    # Create plot without axes or ticks\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"$L=$%g, $N=$%g, $v_0=$%g, $R=$%g, $\\eta=$%g\" %(L,N,v0,R,eta))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.tick_params(bottom='off', left='off')\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Create box\n",
    "    box = plt.Rectangle((-L/2,-L/2), L, L, ec='none', lw=3, fc='none')\n",
    "    box.set_edgecolor('k')\n",
    "    ax.add_patch(box)\n",
    "\n",
    "    # Plot positions and velocities\n",
    "    ax.quiver(state[:,0], state[:,1], state[:,3], state[:,4])\n",
    "\n",
    "    # If argv[3] = save, save the figure\n",
    "    if save == True:\n",
    "        fig_file = argv[2].replace('.out','.png')\n",
    "        fig.savefig(fig_file)\n",
    "\n",
    "    plt.show()\n",
    "   \n",
    "\n",
    "    exit(0)\n",
    "\n",
    "\n",
    "#####################\n",
    "## Plot statistics ##\n",
    "#####################\n",
    "# Argument variables tell us how to organise the data into plots\n",
    "# Possible values:   'N', 'v0', 'R', 'eta'\n",
    "x_var = argv[1] # values of this variable on the x-axis\n",
    "lines_var = argv[2] # values of this variable are different lines on the same plot\n",
    "\n",
    "# Open pdf for saving\n",
    "if save == True:\n",
    "    save_pdf = mpl_pdf.PdfPages(save_name+\".pdf\")\n",
    "\n",
    "# Quick check that argument variables are valid\n",
    "plot_vars = ['N','v0','R','eta']\n",
    "if x_var not in plot_vars or lines_var not in plot_vars:\n",
    "    print (\"Error: invalid argument(s)\")\n",
    "\n",
    "# The other two variables will be separated into separate plots\n",
    "plot_vars.remove(x_var)\n",
    "plot_vars.remove(lines_var)\n",
    "\n",
    "# Load data output by main.py\n",
    "save_file = save_name + \".out\"\n",
    "input_data = np.loadtxt(save_file)\n",
    "\n",
    "# Create dictionary to link string variables with indices for input_data\n",
    "index_dict = {'L': 0, 'N': 1, 'v0': 2, 'R': 3, 'eta': 4,\n",
    "              'V': 5, 'eV': 6, 'chi': 7, 'echi': 8, 'U': 9, 'eU': 10}\n",
    "\n",
    "# Dictionary so that the x-label and plot symbols are a little more fancy\n",
    "xlabel_dict = {'N': \"Number of particles\", 'v0': \"Particle velocity\",\n",
    "               'R': \"Interaction radius\", 'eta': \"Magnitude of heading noise\"}\n",
    "symb_dict = {'N': \"$N$\", 'v0': \"$v_0$\", 'R': \"$R$\", 'eta': \"$\\eta$\"}\n",
    "\n",
    "\n",
    "# Iterate over unique values of the first variable in plot_vars\n",
    "for I in set(list( input_data[:, index_dict[plot_vars[0]] ] )):\n",
    "    Irows = np.where( input_data[:, index_dict[plot_vars[0]] ] == I )[0]\n",
    "    Idata = input_data[Irows, :]\n",
    "    \n",
    "    # Now over unique values of the second variable in plot_vars\n",
    "    for J in set(list( Idata[:, index_dict[plot_vars[1]] ] )):\n",
    "        IJrows = np.where( Idata[:, index_dict[plot_vars[1]] ] == J )[0]\n",
    "        IJdata = Idata[IJrows, :]\n",
    "\n",
    "        # Create plots\n",
    "        fig = plt.figure(figsize=(8,4))\n",
    "        gs = gridspec.GridSpec(1, 3, width_ratios=[1,1,1])\n",
    "        ax = plt.subplot(gs[0])\n",
    "        ax2 = plt.subplot(gs[1])\n",
    "        ax3 = plt.subplot(gs[2])\n",
    "        \n",
    "        ax2.set_title(\"%s = %g, %s = %g\" \n",
    "                %(symb_dict[plot_vars[0]], I, symb_dict[plot_vars[1]], J) )\n",
    "        ax.set_ylabel(\"Order parameter ($V$)\")\n",
    "        ax2.set_ylabel(\"Susceptibility ($\\chi$)\")\n",
    "        ax3.set_ylabel(\"Binder cumulant ($U$)\")\n",
    "        ax.set_xlabel(xlabel_dict[x_var]+\" (\"+symb_dict[x_var]+\")\")\n",
    "        ax2.set_xlabel(xlabel_dict[x_var]+\" (\"+symb_dict[x_var]+\")\")\n",
    "        ax3.set_xlabel(xlabel_dict[x_var]+\" (\"+symb_dict[x_var]+\")\")\n",
    "\n",
    "        # For each unique value of lines_var, plot a line\n",
    "        for K in set(list( IJdata[:, index_dict[lines_var] ] )):\n",
    "            IJKrows = np.where( IJdata[:, index_dict[lines_var] ] == K )[0]\n",
    "            IJKdata = IJdata[IJKrows, :]\n",
    "\n",
    "            # x_var plotted along x-axis\n",
    "            xdata = IJKdata[:, index_dict[x_var] ]\n",
    "\n",
    "            # Get indices which sort xdata into ascending order\n",
    "            srted = np.argsort(xdata)\n",
    "            xdata = xdata[ srted ]\n",
    "            \n",
    "            # Plot Order parameter, susceptibility and Binder cumulent\n",
    "            ax.errorbar(xdata, IJKdata[srted, index_dict['V'] ], \n",
    "                    yerr=IJKdata[srted, index_dict['eV'] ], fmt='.-')\n",
    "            ax2.errorbar(xdata, IJKdata[srted, index_dict['chi'] ], \n",
    "                    yerr=IJKdata[srted, index_dict['echi'] ], fmt='.-')\n",
    "            ax3.errorbar(xdata, IJKdata[srted, index_dict['U'] ], \n",
    "                    yerr=IJKdata[srted, index_dict['eU'] ], fmt='.-',\n",
    "                    label=\"%s=%g\" %(symb_dict[lines_var],K) )\n",
    "\n",
    "        ax3.legend()\n",
    "        plt.tight_layout()\n",
    "    \n",
    "        # Add the figure to the open pdf file\n",
    "        if save == True:\n",
    "            save_pdf.savefig(fig)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# Close the pdf\n",
    "if save == True:\n",
    "    save_pdf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
